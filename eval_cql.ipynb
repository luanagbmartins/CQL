{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "from tensorboardX import SummaryWriter\n",
    "import gin.tf\n",
    "\n",
    "from batch_rl.fixed_replay.agents import quantile_agent\n",
    "from batch_rl.fixed_replay.environments import ACPulse\n",
    "from dopamine.discrete_domains import checkpointer\n",
    "\n",
    "\n",
    "from running_stats import RunningMeanStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512, bias=True)\n",
    "        # nn.init.zeros_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(512, 256, bias=True)\n",
    "        # nn.init.zeros_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(256, 128, bias=True)\n",
    "        self.fc4 = nn.Linear(128, 1, bias=True)\n",
    "        # nn.init.zeros_(self.fc4.weight)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.softp = torch.nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.fc4(x)\n",
    "        # x = self.softp(x)\n",
    "        return x\n",
    "    \n",
    "class RewardPredictor:\n",
    "    def __init__(self, input_size, checkpoint_dir):\n",
    "\n",
    "        self.model = NN(input_size + 1)\n",
    "\n",
    "        self.running_stats = RunningMeanStd()\n",
    "\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state, scheduler_state, running_stats_state = torch.load(\n",
    "            checkpoint\n",
    "        )\n",
    "        self.model.load_state_dict(model_state)\n",
    "        self.running_stats.load_dict(running_stats_state)\n",
    "\n",
    "    def predict(self, x):\n",
    "        scores = self.model(x)\n",
    "        scores_raw = (torch.exp(scores) - 1 + 0.003) * math.sqrt(\n",
    "            (self.running_stats.var)\n",
    "        )  # just the inverse transofrmation for the predicted rewards\n",
    "        return scores_raw\n",
    "    \n",
    "def estimate(predictor, actions, action_probs, obs):\n",
    "    obs = torch.Tensor(\n",
    "        np.concatenate(\n",
    "            (obs, np.reshape(actions, (actions[0].shape[0], 1))), axis=1\n",
    "        )\n",
    "    )  # concatenate actions and observations for input obs are usually [[obs1],[obs2],[obs3]] and\n",
    "    # actions are usually [1,0,1,0] so the goal is to make actions like this: [[1],[0],[1]]\n",
    "    scores_raw = predictor.predict(obs).detach().numpy()\n",
    "    results = {}\n",
    "    results[\"score\"] = (scores_raw * action_probs).mean()\n",
    "    results[\"pred_reward_mean\"] = scores_raw.mean()\n",
    "    results[\"pred_reward_total\"] = scores_raw.sum()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/miniconda3/envs/pulse/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/miniconda3/envs/pulse/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_v2_behavior()\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "_sess = tf.compat.v1.Session('', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating FixedReplayAgent with replay directory: cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating FixedReplayAgent with replay directory: cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\t init_checkpoint_dir: runs/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\t init_checkpoint_dir: runs/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\t replay_suffix None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\t replay_suffix None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Quantile Agent....\n",
      "min Q weight (QR-DQN):  10.0\n",
      "Ckpt suffixes:  ['0' '7' '5' '2' '1' '6' '3' '4']\n",
      "Loading buffer in fixed replay buffer\n",
      "Loading buffer in fixed replay bufferLoading buffer in fixed replay buffer\n",
      "Loading buffer in fixed replay buffer\n",
      "\n",
      "Loading buffer in fixed replay buffer\n",
      "Loading buffer in fixed replay buffer\n",
      "Loading buffer in fixed replay buffer\n",
      "Loading buffer in fixed replay buffer\n",
      "INFO:tensorflow:Loaded replay buffer ckpt 3 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 3 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 0 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 0 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 2 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 2 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 7 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 7 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 4 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 4 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 1 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 1 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 6 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 6 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 5 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded replay buffer ckpt 5 from cql-dataset/v5_scoremax_dataset_cql/replay_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replay buffers:  8\n",
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/helpers.py:107: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/helpers.py:107: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/quantile_agent.py:160: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/quantile_agent.py:160: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/quantile_agent.py:191: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/RL/CQL/batch_rl/multi_head/quantile_agent.py:191: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN Q WEIGHT:  10.0\n",
      "---------- (80,)\n",
      "---------- <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "environment = ACPulse((80,), np.float32)\n",
    "\n",
    "replay_data_dir = \"cql-dataset/v5_scoremax_dataset_cql/replay_logs\"\n",
    "checkpoint_dir = \"runs/checkpoints\"\n",
    "\n",
    "agent = quantile_agent.FixedReplayQuantileAgent(\n",
    "    _sess, \n",
    "    num_actions=environment.action_space.n,\n",
    "    observation_shape=environment.observation_shape,\n",
    "    observation_dtype=environment.observation_dtype,\n",
    "    replay_data_dir=replay_data_dir,\n",
    "    init_checkpoint_dir=checkpoint_dir,\n",
    "    replay_scheme=\"uniform\",\n",
    ")\n",
    "agent.eval_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(path):\n",
    "    print(\"----- Download files from Bucket\")\n",
    "    bucket = storage.Client().get_bucket(\"ac-rl-artifacts\")\n",
    "    blobs = bucket.list_blobs(prefix=path)\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "        os.makedirs(os.path.dirname(blob.name), exist_ok=True)\n",
    "        blob.download_to_filename(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Download files from Bucket\n",
      "models/reward_pred_v0_model/release/80_input/.is_checkpoint\n",
      "models/reward_pred_v0_model/release/80_input/.tune_metadata\n",
      "models/reward_pred_v0_model/release/80_input/checkpoint\n"
     ]
    }
   ],
   "source": [
    "input_size = environment.observation_shape[0]\n",
    "\n",
    "# Get checkpoint dir\n",
    "chkpt_path = \"models/reward_pred_v0_model/release/80_input\"\n",
    "download_files(chkpt_path)\n",
    "\n",
    "# Load reward predictor\n",
    "rew_pred = RewardPredictor(input_size, os.path.abspath(chkpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard Writer\n",
    "save_folder = \"evaluation\"\n",
    "dataset_name = \"test_dataset_users\"\n",
    "dataset_version = \"v5\"\n",
    "\n",
    "writer = SummaryWriter(\n",
    "    os.path.join(save_folder, dataset_name.split(\"_\")[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation dataset\n",
    "dataset_path = \"data/processed/{}_dataset/{}/\".format(\n",
    "    dataset_version, dataset_name\n",
    ")\n",
    "# download_files(dataset_path)\n",
    "validation_dataset = [\n",
    "    os.path.join(dataset_path, f)\n",
    "    for f in os.listdir(dataset_path)\n",
    "    if os.path.isfile(os.path.join(dataset_path, f))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD CHECKPOINT  runs/checkpoints/ckpt.9\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-9\n",
      "100%|██████████| 88/88 [00:48<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm/score                0.053695\n",
      "dm/pred_reward_mean     0.053695\n",
      "dm/pred_reward_total    0.597074\n",
      "dtype: float64\n",
      "LOAD CHECKPOINT  runs/checkpoints/ckpt.10\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-10\n",
      "100%|██████████| 88/88 [00:47<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm/score                0.054368\n",
      "dm/pred_reward_mean     0.054368\n",
      "dm/pred_reward_total    0.599134\n",
      "dtype: float64\n",
      "LOAD CHECKPOINT  runs/checkpoints/ckpt.11\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-11\n",
      "100%|██████████| 88/88 [00:48<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm/score                0.054276\n",
      "dm/pred_reward_mean     0.054276\n",
      "dm/pred_reward_total    0.599352\n",
      "dtype: float64\n",
      "LOAD CHECKPOINT  runs/checkpoints/ckpt.12\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from runs/checkpoints/tf_ckpt-12\n",
      "100%|██████████| 88/88 [00:47<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm/score                0.054109\n",
      "dm/pred_reward_mean     0.054109\n",
      "dm/pred_reward_total    0.600885\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "checkpoints = [9, 10, 11, 12]\n",
    "_checkpointer = checkpointer.Checkpointer(checkpoint_dir, 'ckpt')\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    experiment_data = _checkpointer.load_checkpoint(checkpoint)\n",
    "    agent.unbundle(checkpoint_dir, checkpoint, experiment_data)\n",
    "    agent.eval_mode = True\n",
    "\n",
    "    actions = []\n",
    "    estimation_eps = {\n",
    "        \"dm/score\": [],\n",
    "        \"dm/pred_reward_mean\": [],\n",
    "        \"dm/pred_reward_total\": [],\n",
    "    }\n",
    "    for n_eps in tqdm(range(len(validation_dataset[0]))):\n",
    "        reader = JsonReader(validation_dataset[0])\n",
    "        batch = reader.next()\n",
    "        estimation = {\n",
    "            \"dm/score\": [],\n",
    "            \"dm/pred_reward_mean\": [],\n",
    "            \"dm/pred_reward_total\": [],\n",
    "        }\n",
    "        for episode in batch.split_by_episode():\n",
    "            action = []\n",
    "            action_probs = []\n",
    "            for i in range(len(episode[\"eps_id\"])): \n",
    "                action.append(agent.step(episode[\"rewards\"][i], episode[\"obs\"][i]))\n",
    "                action_probs.append(1.0)\n",
    "                \n",
    "                \n",
    "            actions.extend(action)\n",
    "            action = np.array([action])\n",
    "            action_probs = np.array([action_probs])\n",
    "            scores = estimate(rew_pred, action, action_probs, episode[\"obs\"])\n",
    "            estimation[\"dm/score\"].append(scores[\"score\"])\n",
    "            estimation[\"dm/pred_reward_mean\"].append(scores[\"pred_reward_mean\"])\n",
    "            estimation[\"dm/pred_reward_total\"].append(scores[\"pred_reward_total\"])\n",
    "            \n",
    "        estimation_eps[\"dm/score\"].append(mean(estimation[\"dm/score\"]))\n",
    "        estimation_eps[\"dm/pred_reward_mean\"].append(mean(estimation[\"dm/pred_reward_mean\"]))\n",
    "        estimation_eps[\"dm/pred_reward_total\"].append(mean(estimation[\"dm/pred_reward_total\"]))\n",
    "                        \n",
    "    est_mean = pd.DataFrame.from_dict(estimation_eps).mean(axis=0)\n",
    "    print(est_mean.head())\n",
    "    \n",
    "    # DM Estimation ------------------------\n",
    "    writer.add_scalar(\n",
    "        \"evaluation/dm/score\", est_mean[\"dm/score\"], checkpoint\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        \"evaluation/dm/pred_reward_mean\",\n",
    "        est_mean[\"dm/pred_reward_mean\"],\n",
    "        checkpoint,\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        \"evaluation/dm/pred_reward_mean_total\",\n",
    "        est_mean[\"dm/pred_reward_total\"],\n",
    "        checkpoint,\n",
    "    )\n",
    "    \n",
    "    # Action\n",
    "    writer.add_scalar(\n",
    "        \"evaluation/actions_prob\",\n",
    "        float(actions.count(1)) / len(actions),\n",
    "        checkpoint,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dm/score                0.054293\n",
       "dm/pred_reward_mean     0.054293\n",
       "dm/pred_reward_total    0.600544\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
